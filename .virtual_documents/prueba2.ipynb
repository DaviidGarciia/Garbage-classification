


# Importar bibliotecas necesarias
import os
import matplotlib.pyplot as plt
from collections import Counter
from PIL import Image

# Ruta al dataset descargado
dataset_path = "Garbage classification" 

# 1. Cargar el dataset y explorar carpetas
def explorar_dataset(path):
    clases = os.listdir(path)
    print(f"Clases disponibles: {clases}")
    total_imagenes = 0
    distribucion = {}
    for clase in clases:
        clase_path = os.path.join(path, clase)
        imagenes = os.listdir(clase_path)
        distribucion[clase] = len(imagenes)
        total_imagenes += len(imagenes)
    print(f"Total de imágenes: {total_imagenes}")
    return distribucion

distribucion = explorar_dataset(dataset_path)


# 2. Visualizar la distribución de clases
def visualizar_distribucion(distribucion):
    clases, cantidades = zip(*distribucion.items())
    plt.bar(clases, cantidades)
    plt.xlabel('Clases')
    plt.ylabel('Cantidad de Imágenes')
    plt.title('Distribución de Clases')
    plt.xticks(rotation=45)
    plt.show()

visualizar_distribucion(distribucion)


import os
import requests
from tqdm import tqdm
from PIL import Image, ImageEnhance, ImageOps
import random

# Función para aplicar aumentaciones
def augment_image(image, output_folder, base_name, augment_count):
    """
    Aplica transformaciones a la imagen para aumentar el dataset.
    """
    for i in range(augment_count):
        # Realiza transformaciones aleatorias
        img = image.copy()
        
        # Rotación aleatoria entre -15° y 15°
        angle = random.randint(-15, 15)
        img = img.rotate(angle)

        # Volteo horizontal con 50% de probabilidad
        if random.random() > 0.5:
            img = ImageOps.mirror(img)

        # Ajuste de brillo aleatorio (80% a 120%)
        enhancer = ImageEnhance.Brightness(img)
        brightness = random.uniform(0.8, 1.2)
        img = enhancer.enhance(brightness)

        # Ajuste de contraste aleatorio (80% a 120%)
        enhancer = ImageEnhance.Contrast(img)
        contrast = random.uniform(0.8, 1.2)
        img = enhancer.enhance(contrast)

        # Guardar la imagen aumentada
        output_path = os.path.join(output_folder, f"{base_name}_aug_{i}.jpg")
        img.save(output_path)

# Función para descargar y procesar imágenes
def download_and_augment_images(url_file, category_folder, target_size=(128, 128), augment_count=4):
    """
    Descarga imágenes desde un archivo de texto con URLs, las procesa (redimensiona y aumenta)
    y las guarda en la carpeta indicada.
    """
    os.makedirs(category_folder, exist_ok=True)

    with open(url_file, 'r') as file:
        urls = file.readlines()

    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}

    for i, url in enumerate(tqdm(urls, desc=f"Procesando imágenes para {category_folder}")):
        url = url.strip()
        if not url:
            continue
        try:
            response = requests.get(url, stream=True, timeout=10, headers=headers)
            response.raise_for_status()

            # Obtener la extensión válida
            file_extension = url.split('.')[-1].split('?')[0].lower()
            if file_extension not in ['jpg', 'jpeg', 'png', 'gif', 'webp']:
                file_extension = 'jpg'

            # Crear nombre base del archivo
            base_name = f"{category_folder.split(os.sep)[-1]}_{i}"

            # Guardar la imagen original
            image_path = os.path.join(category_folder, f"{base_name}.jpg")
            with open(image_path, 'wb') as img_file:
                img_file.write(response.content)

            # Abrir la imagen, redimensionarla y generar aumentaciones
            img = Image.open(image_path).convert("RGB")
            img = img.resize(target_size)

            # Guardar la imagen redimensionada
            img.save(image_path)

            # Aplicar aumentaciones
            augment_image(img, category_folder, base_name, augment_count)
        except Exception as e:
            print(f"Error descargando {url}: {e}")

# Directorio principal y archivos de entrada
base_dir = "./Garbage classification"
categories = {
    "trash": "trash.txt",
    "plastic": "plastic.txt",
    "paper": "paper.txt",
    "metal": "metal.txt",
    "glass": "glass.txt",
    "cardboard": "cardboard.txt"
}

# Descargar y procesar imágenes para cada categoría
for category, file_name in categories.items():
    file_path = f"./{file_name}"  # Asegúrate de que los archivos están en el mismo nivel que el notebook
    category_folder = os.path.join(base_dir, category)
    download_and_augment_images(file_path, category_folder, target_size=(128, 128), augment_count=4)



# 3. Mostrar ejemplos de imágenes
def mostrar_imagenes(path, clase, num_imagenes=5):
    clase_path = os.path.join(path, clase)
    imagenes = os.listdir(clase_path)[:num_imagenes]
    plt.figure(figsize=(15, 5))
    for i, img_name in enumerate(imagenes):
        img_path = os.path.join(clase_path, img_name)
        img = Image.open(img_path)
        plt.subplot(1, num_imagenes, i + 1)
        plt.imshow(img)
        plt.axis('off')
        plt.title(clase)
    plt.show()

# Mostrar imágenes de cada clase (muestra un ejemplo por clase)
for clase in distribucion.keys():
    mostrar_imagenes(dataset_path, clase)


# Importar bibliotecas necesarias
import os

# Ruta al dataset descargado
dataset_path = "Garbage classification"

# Función para contar imágenes por categoría
def contar_imagenes_por_categoria(path):
    clases = os.listdir(path)
    conteo_categorias = {}
    for clase in clases:
        clase_path = os.path.join(path, clase)
        if os.path.isdir(clase_path):  # Asegurarse de que sea un directorio
            num_imagenes = len([f for f in os.listdir(clase_path) if os.path.isfile(os.path.join(clase_path, f))])
            conteo_categorias[clase] = num_imagenes
    return conteo_categorias

# Obtener y mostrar el conteo
conteo = contar_imagenes_por_categoria(dataset_path)

# Mostrar el conteo en consola
print("Conteo de imágenes por categoría:")
for categoria, cantidad in conteo.items():
    print(f"{categoria}: {cantidad} imágenes")


from PIL import Image, ImageOps
import random
import os

# Función para aumentar las imágenes en cada categoría
def aumentar_imagenes(dataset_path, max_images=594):
    clases = os.listdir(dataset_path)
    for clase in clases:
        clase_path = os.path.join(dataset_path, clase)
        if os.path.isdir(clase_path):
            imagenes = os.listdir(clase_path)
            num_actual = len(imagenes)
            print(f"Aumentando la clase '{clase}' de {num_actual} a {max_images} imágenes...")
            
            while num_actual < max_images:
                # Elegir una imagen al azar para aumentación
                img_name = random.choice(imagenes)
                img_path = os.path.join(clase_path, img_name)
                with Image.open(img_path) as img:
                    # Realizar transformaciones aleatorias
                    transformacion = random.choice(["flip", "rotate"])
                    if transformacion == "flip":
                        img_aumentada = ImageOps.mirror(img)
                    elif transformacion == "rotate":
                        img_aumentada = img.rotate(random.choice([90, 180, 270]))
                    
                    # Guardar la imagen aumentada
                    nueva_imagen_nombre = f"{clase}_{num_actual}.jpg"
                    nueva_imagen_path = os.path.join(clase_path, nueva_imagen_nombre)
                    img_aumentada.save(nueva_imagen_path)
                    
                    # Actualizar el contador
                    num_actual += 1

# Ruta del dataset
dataset_path = "Garbage classification"  # Cambia esto a tu ruta real

# Aumentar imágenes en todas las categorías
aumentar_imagenes(dataset_path)

# Verificar conteo después de la aumentación
conteo_post_aumentacion = contar_imagenes_por_categoria(dataset_path)

# Mostrar el nuevo conteo
print("\nNuevo conteo de imágenes por categoría después de la aumentación:")
for categoria, cantidad in conteo_post_aumentacion.items():
    print(f"{categoria}: {cantidad} imágenes")

# Mostrar 2 imágenes por categoría
def mostrar_dos_imagenes_por_categoria(path, categorias):
    for clase in categorias:
        clase_path = os.path.join(path, clase)
        imagenes = os.listdir(clase_path)[:2]
        plt.figure(figsize=(8, 4))
        for i, img_name in enumerate(imagenes):
            img_path = os.path.join(clase_path, img_name)
            img = Image.open(img_path)
            plt.subplot(1, 2, i + 1)
            plt.imshow(img)
            plt.axis('off')
            plt.title(clase)
        plt.show()

mostrar_dos_imagenes_por_categoria(dataset_path, conteo_post_aumentacion.keys())





import os
from PIL import Image

# Ruta del dataset
dataset_path = "Garbage classification"  # Cambia esto a tu ruta real

# Ruta para guardar las imágenes redimensionadas
resized_dataset_path = "Garbage classification resized"
os.makedirs(resized_dataset_path, exist_ok=True)

# Redimensionar imágenes
def redimensionar_imagenes(input_path, output_path, target_size=(224, 224)):
    for root, dirs, files in os.walk(input_path):
        for dir_name in dirs:
            # Crear directorios de salida para cada categoría
            input_dir = os.path.join(root, dir_name)
            output_dir = os.path.join(output_path, dir_name)
            os.makedirs(output_dir, exist_ok=True)
            
            for file_name in os.listdir(input_dir):
                if file_name.endswith(('.png', '.jpg', '.jpeg')):
                    input_file_path = os.path.join(input_dir, file_name)
                    output_file_path = os.path.join(output_dir, file_name)
                    
                    # Redimensionar y guardar la imagen
                    with Image.open(input_file_path) as img:
                        img_resized = img.resize(target_size)
                        img_resized.save(output_file_path)

# Ejecutar la redimensión
redimensionar_imagenes(dataset_path, resized_dataset_path)

print(f"Imágenes redimensionadas y guardadas en: {resized_dataset_path}")



import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input, decode_predictions
import numpy as np
from PIL import Image
import os

# 1. Cargar el modelo preentrenado
model = EfficientNetB0(weights='imagenet')  # Modelo preentrenado
model.summary()  # Opcional: Ver la estructura del modelo

# 2. Función para cargar imágenes ya redimensionadas y aplicar preprocesamiento
def load_image(img_path):
    img = Image.open(img_path).convert('RGB')  # Asegurarse de que sea RGB
    img_array = np.array(img)  # Convertir a array numpy
    img_array = preprocess_input(img_array)  # Normalizar para EfficientNet
    return np.expand_dims(img_array, axis=0)  # Añadir dimensión de batch

# 3. Probar el modelo con imágenes redimensionadas
dataset_path = "Garbage classification resized"  # Cambia a la ruta redimensionada
categories = os.listdir(dataset_path)  # Obtener categorías

print("Probando el modelo en imágenes del dataset:")
for category in categories:
    category_path = os.path.join(dataset_path, category)
    images = [os.path.join(category_path, f) for f in os.listdir(category_path) if f.endswith(('.png', '.jpg', '.jpeg'))]
    
    # Probar las primeras 2 imágenes de cada categoría
    for img_path in images[:2]:
        input_tensor = load_image(img_path)  # Cargar y preprocesar imagen
        predictions = model.predict(input_tensor)  # Realizar predicción
        decoded_predictions = decode_predictions(predictions, top=3)[0]  # Decodificar las 3 mejores predicciones

        # Mostrar resultados
        print(f"\nImagen: {img_path}")
        for i, (class_id, class_name, confidence) in enumerate(decoded_predictions):
            print(f"  {i+1}. {class_name}: {confidence:.2f}")






import os
import pandas as pd
from sklearn.model_selection import train_test_split

# Ruta al dataset
dataset_path = "Garbage classification resized"  # Cambia esto a tu ruta redimensionada

# Obtener todas las imágenes y sus etiquetas
def obtener_imagenes_y_etiquetas(path):
    data = []
    categories = os.listdir(path)
    for category in categories:
        category_path = os.path.join(path, category)
        if os.path.isdir(category_path):
            images = [os.path.join(category_path, img) for img in os.listdir(category_path) if img.endswith(('.png', '.jpg', '.jpeg'))]
            for img in images:
                data.append({"path": img, "label": category})
    return pd.DataFrame(data)

# Crear DataFrame de imágenes y etiquetas
df = obtener_imagenes_y_etiquetas(dataset_path)
print(f"Total de imágenes: {len(df)}")

# Dividir en train (80%) y test (20%)
train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)

# Mostrar conteo de cada categoría en train y test
print("\nDistribución en train:")
print(train_df['label'].value_counts())
print("\nDistribución en test:")
print(test_df['label'].value_counts())

# Guardar los DataFrames en archivos CSV (opcional)
train_df.to_csv("train_data.csv", index=False)
test_df.to_csv("test_data.csv", index=False)

print("\nDivisión completada. Archivos guardados como 'train_data.csv' y 'test_data.csv'")



# Importar EfficientNetB0 para verificar el número de capas
from tensorflow.keras.applications import EfficientNetB0

# Cargar el modelo preentrenado
model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Número total de capas en EfficientNetB0
num_layers = len(model.layers)
num_layers
# Hemos visto que el modelo preentrenado tiene 238 capas y cogeremos solo las últimas 38 capas


import os
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras import layers, models
from tensorflow.keras import regularizers
import tensorflow as tf
import matplotlib.pyplot as plt

# Ruta al dataset
dataset_path = "Garbage classification resized"  # Cambia esto a tu ruta redimensionada

# Obtener todas las imágenes y sus etiquetas
def obtener_imagenes_y_etiquetas(path):
    data = []
    categories = os.listdir(path)
    for category in categories:
        category_path = os.path.join(path, category)
        if os.path.isdir(category_path):
            images = [os.path.join(category_path, img) for img in os.listdir(category_path) if img.endswith(('.png', '.jpg', '.jpeg'))]
            for img in images:
                data.append({"path": img, "label": category})
    return pd.DataFrame(data)

# Crear DataFrame de imágenes y etiquetas
df = obtener_imagenes_y_etiquetas(dataset_path)
print(f"Total de imágenes: {len(df)}")

# Dividir en train (80%) y test (20%)
train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)

# Mostrar conteo de cada categoría en train y test
print("\nDistribución en train:")
print(train_df['label'].value_counts())
print("\nDistribución en test:")
print(test_df['label'].value_counts())

# Guardar los DataFrames en archivos CSV (opcional)
train_df.to_csv("train_data.csv", index=False)
test_df.to_csv("test_data.csv", index=False)

print("\nDivisión completada. Archivos guardados como 'train_data.csv' y 'test_data.csv'")

# Crear generadores de datos con aumentación
from tensorflow.keras.applications.efficientnet import preprocess_input

IMG_SIZE = (224, 224)
BATCH_SIZE = 16
EPOCHS = 50
LEARNING_RATE = 0.0001

train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)

test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

# Configurar generadores
train_generator = train_datagen.flow_from_dataframe(
    dataframe=train_df,
    x_col="path",
    y_col="label",
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="categorical"
)

test_generator = test_datagen.flow_from_dataframe(
    dataframe=test_df,
    x_col="path",
    y_col="label",
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="categorical"
)

# ====================
# 3. Construcción del Modelo
# ====================

# Cargar modelo preentrenado EfficientNetB0
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Congelar las primeras capas (opcional: ajustar el rango para datos específicos)
for layer in base_model.layers[:-100]:  # Ajusta el rango según sea necesario
    layer.trainable = False
for layer in base_model.layers[-100:]:  # este es el que tenemos que coger 
    layer.trainable = True

# Construir modelo personalizado
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dropout(0.6),  # Aumentar Dropout
    layers.Dense(6, activation='softmax', kernel_regularizer=regularizers.l2(0.01))  # Corregido
])

# Resumen del modelo
model.summary()

# ====================
# 4. Compilación del Modelo
# ====================

# Compilar el modelo
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Ajustar el nombre del archivo para cumplir con el formato Keras
callbacks = [
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)  # Cambiado a .keras
]

history = model.fit(
    train_generator,
    validation_data=test_generator,
    epochs=EPOCHS,
    steps_per_epoch=train_generator.samples // BATCH_SIZE,
    validation_steps=test_generator.samples // BATCH_SIZE,
    callbacks=callbacks
)

# Guardar el modelo entrenado en formato Keras
model.save("garbage_classifier_efficientnet.keras")  # Cambiado a .keras
print("Modelo entrenado y guardado como 'garbage_classifier_efficientnet.keras'")

# ====================
# 6. Evaluación y Visualización
# ====================

# Gráfica de precisión
plt.figure(figsize=(8, 4))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Precisión del Modelo')
plt.show()

# Gráfica de pérdida
plt.figure(figsize=(8, 4))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Pérdida del Modelo')
plt.show()



from tensorflow.keras.models import load_model
from tensorflow.keras.applications.efficientnet import preprocess_input
import numpy as np
from PIL import Image
import requests
from io import BytesIO
import matplotlib.pyplot as plt

# ====================
# 1. Cargar el modelo entrenado
# ====================
# Asegúrate de haber entrenado y guardado el modelo previamente
model = load_model("garbage_classifier_efficientnet.keras")
print("Modelo cargado exitosamente.")

# ====================
# 2. Función para preprocesar una imagen
# ====================
def preprocess_image(img_path, target_size=(224, 224)):
    """
    Preprocesa una imagen desde una ruta local.
    """
    img = Image.open(img_path).convert('RGB')  # Convertir a RGB
    img = img.resize(target_size)  # Redimensionar a 224x224
    img_array = np.array(img)  # Convertir a array numpy
    img_array = preprocess_input(img_array)  # Aplicar preprocesamiento de EfficientNet
    return np.expand_dims(img_array, axis=0)  # Añadir dimensión de batch

# ====================
# 3. Cargar y preprocesar imágenes desde una URL
# ====================
def load_image_from_url(url, target_size=(224, 224)):
    """
    Descarga una imagen desde una URL, la redimensiona y la preprocesa.
    """
    response = requests.get(url)
    if response.status_code == 200:
        img = Image.open(BytesIO(response.content)).convert('RGB')
        img = img.resize(target_size)  # Redimensionar a 224x224
        img_array = np.array(img)  # Convertir a array numpy
        img_array = preprocess_input(img_array)  # Aplicar preprocesamiento de EfficientNet
        return np.expand_dims(img_array, axis=0)  # Añadir dimensión de batch
    else:
        raise Exception(f"Error al descargar la imagen. Código de estado: {response.status_code}")

# ====================
# 4. Predicción con condición
# ====================
def predict_image_from_url_or_path(img_path_or_url, threshold=0.5, target_size=(224, 224)):
    """
    Predice si una imagen es basura o "otros" desde una ruta local o URL.
    """
    # Determinar si es una URL o una ruta local
    if img_path_or_url.startswith("http://") or img_path_or_url.startswith("https://"):
        input_tensor = load_image_from_url(img_path_or_url, target_size)
    else:
        input_tensor = preprocess_image(img_path_or_url, target_size)
    
    # Realizar predicción
    predictions = model.predict(input_tensor)
    predicted_class = np.argmax(predictions, axis=1)[0]
    confidence = np.max(predictions)  # Confianza de la predicción más alta

    # Nombres de las clases (cambia según tu dataset)
    class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']
    
    # Condicional: Si la confianza es baja para todas las clases
    if confidence < threshold:
        return "Otros (No es basura)", confidence
    else:
        return class_names[predicted_class], confidence

# ====================
# 5. Mostrar la imagen y predicción
# ====================
def predict_and_show_from_url_or_path(img_path_or_url, threshold=0.5, target_size=(224, 224)):
    """
    Predice si una imagen es basura o "otros" y la muestra con la predicción.
    """
    # Cargar la imagen desde URL o ruta
    if img_path_or_url.startswith("http://") or img_path_or_url.startswith("https://"):
        response = requests.get(img_path_or_url)
        img = Image.open(BytesIO(response.content)).convert('RGB')
    else:
        img = Image.open(img_path_or_url)
    
    # Realizar predicción
    predicted_class, confidence = predict_image_from_url_or_path(img_path_or_url, threshold, target_size)
    
    # Mostrar la imagen
    plt.imshow(img)
    plt.title(f"Predicción: {predicted_class} ({confidence:.2f})")
    plt.axis('off')
    plt.show()

# ====================
# 6. Pruebas con imágenes locales o de internet
# ====================

# Prueba con una imagen local
#local_image_path = "ruta_a_tu_imagen_local.jpg"  # Cambia esto por la ruta de una imagen local
#predict_and_show_from_url_or_path(local_image_path)

# Prueba con una imagen de internet
internet_image_url = "https://phantom-elmundo.unidadeditorial.es/0c5fabe33f6b2553ce313b9200a9c8d7/crop/10x59/1022x732/resize/414/f/jpg/assets/multimedia/imagenes/2020/03/23/15849910497221.jpg"  # Cambia esto por una URL
predict_and_show_from_url_or_path(internet_image_url)




